# Классификация токсичных комментариев с помощью BERT Embeddings. Обработка естественного языка

**Описание задачи:** Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. Необходимо обучить модель классифицировать комментарии на позитивные и негативные. В нашем распоряжении набор данных с разметкой о токсичности правок. Построить модель со значением метрики качества F1 не меньше 0.75. 


**Используемые библиотеки:** 
1. Torch
2. Transformers
3. SpaCy
4. NLTK
5. scikit-learn
6. wordcloud
7. VADER
8. re
9. pandas
10. numpy
11. matplotlib
12. seaborn
13. CatBoost


**Используемые алгоритмы и методы:**
* Работа с сильным дисбалансом классов
* Применение transformers. Получение Embeddings с помощью ToxicBERT 
* Предобработка текста и применение алгоритмов лемматизации в Spacy и NLTK
* Анализ тональности текста VADER
* Feature Engeneering
* Работа с регулярными выражениями
* Построение Pipeline
* Подбор порога
* Применение бибилиотеки CatBoost для обработки текстов и сравнительный анализ модернизаций
* TfidfVectorizer
* LogisticRegression
